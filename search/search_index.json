{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Ergo \u00b6 Introduction \u00b6 Ergo is a client library to run application tasks on a shared pool of workers. It is a generic implementation to handle offloading tasks. \u201cServices\u201d are written to actually receive the message and then the runtime \u201cJob Controller\u201d actually runs the relevant functions annotated with the provided \u201ctaskId\u201d. Why use it? \u00b6 If you\u2019ve got long-running tasks, implemented in Java/Kotlin, that you\u2019d like to run from any other microservice, then you can benefit from the declarative and ease-of-use functionality of Ergo. More likely than not, since gRPC and HTTP calls would just timeout for really long-running tasks, Ergo SQS service would provide a feasible approach to use SQS for communication of task requests and executed job results. Even if you\u2019d like to use some service other than SQS for communication, you can make use of core Ergo logic, in ergo-runtime project, to implement your own custom service. Installation \u00b6 Add dependencies to kotlinx.serialization (required by the generated code): \u00b6 Kotlin DSL (build.gradle.kts) repositories { // artifacts are published to JCenter jcenter () maven ( url = \"https://jitpack.io\" ) } plugins { kotlin ( \"plugin.serialization\" ) version kotlinVersion } dependencies { implementation ( kotlin ( \"stdlib\" , KotlinCompilerVersion . VERSION )) // or \"stdlib-jdk8\" implementation ( \"org.jetbrains.kotlinx:kotlinx-serialization-runtime:0.20.0\" ) // JVM dependency } Groovy (build.gradle) repositories { // artifacts are published to JCenter jcenter() maven { url \"https://jitpack.io\" } } plugins { id 'org.jetbrains.kotlin.plugin.serialization' version kotlinVersion } dependencies { implementation \"org.jetbrains.kotlin:kotlin-stdlib:$kotlin_version\" // or \"kotlin-stdlib-jdk8\" implementation \"org.jetbrains.kotlinx:kotlinx-serialization-runtime:0.20.0\" // JVM dependency } Add dependencies to Ergo annotation processor: \u00b6 Add following to Gradle: Kotlin DSL (build.gradle.kts) plugins { kotlin ( \"kapt\" ) version kotlinVersion // Enable kapt plugin for annotation processing } dependencies { kapt ( \"com.github.headout.ergo-kotlin:ergo-processor:1.2.0\" ) } Groovy (build.gradle) plugins { id 'org.jetbrains.kotlin.kapt' version kotlinVersion // Enable kapt plugin for annotation processing } dependencies { kapt \"com.github.headout.ergo-kotlin:ergo-processor:1.2.0\" } Using SQS queue for receiving tasks \u00b6 Add following to Gradle: Kotlin DSL (build.gradle.kts) dependencies { implementation ( platform ( \"software.amazon.awssdk:bom:2.13.26\" )) implementation ( \"software.amazon.awssdk:sqs\" ) implementation ( \"com.github.headout.ergo-kotlin:ergo-service-sqs:1.2.0\" ) } Groovy (build.gradle) dependencies { implementation platform(\"software.amazon.awssdk:bom:2.13.26\") implementation \"software.amazon.awssdk:sqs\" implementation \"com.github.headout.ergo-kotlin:ergo-service-sqs:1.2.0\" } Optional: Using Spring Services and Autowired properties \u00b6 Add following to Gradle: Kotlin DSL (build.gradle.kts) dependencies { implementation ( \"com.github.headout.ergo-kotlin:ergo-spring:1.2.0\" ) } Groovy (build.gradle) dependencies { implementation \"com.github.headout.ergo-kotlin:ergo-spring:1.2.0\" } Documentation \u00b6 Refer to Samples to check out example usages. Architecture \u00b6 Terminology \u00b6 Task => used to denote an executable function with given input and given output Has TaskId to uniquely differentiate tasks Can be used to refer to both regular and suspending functions Function Parameters must be serializable (using @Serializable on the data class) The task function can either be regular or suspending function, and its return type is the job result type too (which must again be serializable) TaskId => name to map to a particular function (must be unique in project). For SQS FIFO queues, it is analogous to MessageGroupId For Pulsar, it is analogous to Topic JobId => uniquely generated from the sender side to denote a particular running instance of a task. For SQS queues, it is analogous to MessageId","title":"Overview"},{"location":"#ergo","text":"","title":"Ergo"},{"location":"#introduction","text":"Ergo is a client library to run application tasks on a shared pool of workers. It is a generic implementation to handle offloading tasks. \u201cServices\u201d are written to actually receive the message and then the runtime \u201cJob Controller\u201d actually runs the relevant functions annotated with the provided \u201ctaskId\u201d.","title":"Introduction"},{"location":"#why-use-it","text":"If you\u2019ve got long-running tasks, implemented in Java/Kotlin, that you\u2019d like to run from any other microservice, then you can benefit from the declarative and ease-of-use functionality of Ergo. More likely than not, since gRPC and HTTP calls would just timeout for really long-running tasks, Ergo SQS service would provide a feasible approach to use SQS for communication of task requests and executed job results. Even if you\u2019d like to use some service other than SQS for communication, you can make use of core Ergo logic, in ergo-runtime project, to implement your own custom service.","title":"Why use it?"},{"location":"#installation","text":"","title":"Installation"},{"location":"#add-dependencies-to-kotlinxserialization-required-by-the-generated-code","text":"Kotlin DSL (build.gradle.kts) repositories { // artifacts are published to JCenter jcenter () maven ( url = \"https://jitpack.io\" ) } plugins { kotlin ( \"plugin.serialization\" ) version kotlinVersion } dependencies { implementation ( kotlin ( \"stdlib\" , KotlinCompilerVersion . VERSION )) // or \"stdlib-jdk8\" implementation ( \"org.jetbrains.kotlinx:kotlinx-serialization-runtime:0.20.0\" ) // JVM dependency } Groovy (build.gradle) repositories { // artifacts are published to JCenter jcenter() maven { url \"https://jitpack.io\" } } plugins { id 'org.jetbrains.kotlin.plugin.serialization' version kotlinVersion } dependencies { implementation \"org.jetbrains.kotlin:kotlin-stdlib:$kotlin_version\" // or \"kotlin-stdlib-jdk8\" implementation \"org.jetbrains.kotlinx:kotlinx-serialization-runtime:0.20.0\" // JVM dependency }","title":"Add dependencies to kotlinx.serialization (required by the generated code):"},{"location":"#add-dependencies-to-ergo-annotation-processor","text":"Add following to Gradle: Kotlin DSL (build.gradle.kts) plugins { kotlin ( \"kapt\" ) version kotlinVersion // Enable kapt plugin for annotation processing } dependencies { kapt ( \"com.github.headout.ergo-kotlin:ergo-processor:1.2.0\" ) } Groovy (build.gradle) plugins { id 'org.jetbrains.kotlin.kapt' version kotlinVersion // Enable kapt plugin for annotation processing } dependencies { kapt \"com.github.headout.ergo-kotlin:ergo-processor:1.2.0\" }","title":"Add dependencies to Ergo annotation processor:"},{"location":"#using-sqs-queue-for-receiving-tasks","text":"Add following to Gradle: Kotlin DSL (build.gradle.kts) dependencies { implementation ( platform ( \"software.amazon.awssdk:bom:2.13.26\" )) implementation ( \"software.amazon.awssdk:sqs\" ) implementation ( \"com.github.headout.ergo-kotlin:ergo-service-sqs:1.2.0\" ) } Groovy (build.gradle) dependencies { implementation platform(\"software.amazon.awssdk:bom:2.13.26\") implementation \"software.amazon.awssdk:sqs\" implementation \"com.github.headout.ergo-kotlin:ergo-service-sqs:1.2.0\" }","title":"Using SQS queue for receiving tasks"},{"location":"#optional-using-spring-services-and-autowired-properties","text":"Add following to Gradle: Kotlin DSL (build.gradle.kts) dependencies { implementation ( \"com.github.headout.ergo-kotlin:ergo-spring:1.2.0\" ) } Groovy (build.gradle) dependencies { implementation \"com.github.headout.ergo-kotlin:ergo-spring:1.2.0\" }","title":"Optional: Using Spring Services and Autowired properties"},{"location":"#documentation","text":"Refer to Samples to check out example usages.","title":"Documentation"},{"location":"#architecture","text":"","title":"Architecture"},{"location":"#terminology","text":"Task => used to denote an executable function with given input and given output Has TaskId to uniquely differentiate tasks Can be used to refer to both regular and suspending functions Function Parameters must be serializable (using @Serializable on the data class) The task function can either be regular or suspending function, and its return type is the job result type too (which must again be serializable) TaskId => name to map to a particular function (must be unique in project). For SQS FIFO queues, it is analogous to MessageGroupId For Pulsar, it is analogous to Topic JobId => uniquely generated from the sender side to denote a particular running instance of a task. For SQS queues, it is analogous to MessageId","title":"Terminology"},{"location":"changelog/","text":"Changelog \u00b6 All notable changes to this project will be documented in this file. See standard-version for commit guidelines. 1.2.0 (2020-09-24) \u00b6 Features \u00b6 add immediate respond result handler ( 80daf60 ) add jobParser to job result handlers ( f1350af ) added dokka plugin for doc generation ( 2b2845e ) generate deserializeJobResult in job parser ( f62fc95 ) modularize result handler to give flexibility to client ( 771cc93 ) Bug Fixes \u00b6 fixed tests for sqs service with buffered results ( 6cf387a ) 1.1.5 (2020-09-24) \u00b6 Bug Fixes \u00b6 use fixed threadpool and runJob without context switch ( 4d6f42e ) use IO dispatcher for ping message ( 48ae379 ) 1.1.4 (2020-09-24) \u00b6 Bug Fixes \u00b6 add to pending job only if processing ( 59c8d5b ) parse 404 results too ( 32af477 ) 1.1.2 (2020-09-24) \u00b6 Bug Fixes \u00b6 complete stacktrace (with cause) in error metadata ( 7b4c7d4 ) 1.1.1 (2020-09-24) \u00b6 Bug Fixes \u00b6 add optional param for nullable types ( a2bf2be ) choose log level for received messages ( b22a44f ) 1.1.0 (2020-09-24) \u00b6 Features \u00b6 fetch visibility timeout if not provided ( d94545c ) Bug Fixes \u00b6 check and throw error when creating spring bean ( a765c6a ) 1.0.2 (2020-09-24) \u00b6 Bug Fixes \u00b6 All SQS unit tests pass now ( dde44b0 ) visibility timeout ping delay is wrongly in seconds ( 910c7a9 ) 1.0.1 (2020-09-24) \u00b6 Bug Fixes \u00b6 java tests failing due to static task functions ( f2f37dc ) support Unit return type on Task function ( c15567e )","title":"Change Log"},{"location":"changelog/#changelog","text":"All notable changes to this project will be documented in this file. See standard-version for commit guidelines.","title":"Changelog"},{"location":"changelog/#120-2020-09-24","text":"","title":"1.2.0 (2020-09-24)"},{"location":"changelog/#features","text":"add immediate respond result handler ( 80daf60 ) add jobParser to job result handlers ( f1350af ) added dokka plugin for doc generation ( 2b2845e ) generate deserializeJobResult in job parser ( f62fc95 ) modularize result handler to give flexibility to client ( 771cc93 )","title":"Features"},{"location":"changelog/#bug-fixes","text":"fixed tests for sqs service with buffered results ( 6cf387a )","title":"Bug Fixes"},{"location":"changelog/#115-2020-09-24","text":"","title":"1.1.5 (2020-09-24)"},{"location":"changelog/#bug-fixes_1","text":"use fixed threadpool and runJob without context switch ( 4d6f42e ) use IO dispatcher for ping message ( 48ae379 )","title":"Bug Fixes"},{"location":"changelog/#114-2020-09-24","text":"","title":"1.1.4 (2020-09-24)"},{"location":"changelog/#bug-fixes_2","text":"add to pending job only if processing ( 59c8d5b ) parse 404 results too ( 32af477 )","title":"Bug Fixes"},{"location":"changelog/#112-2020-09-24","text":"","title":"1.1.2 (2020-09-24)"},{"location":"changelog/#bug-fixes_3","text":"complete stacktrace (with cause) in error metadata ( 7b4c7d4 )","title":"Bug Fixes"},{"location":"changelog/#111-2020-09-24","text":"","title":"1.1.1 (2020-09-24)"},{"location":"changelog/#bug-fixes_4","text":"add optional param for nullable types ( a2bf2be ) choose log level for received messages ( b22a44f )","title":"Bug Fixes"},{"location":"changelog/#110-2020-09-24","text":"","title":"1.1.0 (2020-09-24)"},{"location":"changelog/#features_1","text":"fetch visibility timeout if not provided ( d94545c )","title":"Features"},{"location":"changelog/#bug-fixes_5","text":"check and throw error when creating spring bean ( a765c6a )","title":"Bug Fixes"},{"location":"changelog/#102-2020-09-24","text":"","title":"1.0.2 (2020-09-24)"},{"location":"changelog/#bug-fixes_6","text":"All SQS unit tests pass now ( dde44b0 ) visibility timeout ping delay is wrongly in seconds ( 910c7a9 )","title":"Bug Fixes"},{"location":"changelog/#101-2020-09-24","text":"","title":"1.0.1 (2020-09-24)"},{"location":"changelog/#bug-fixes_7","text":"java tests failing due to static task functions ( f2f37dc ) support Unit return type on Task function ( c15567e )","title":"Bug Fixes"},{"location":"ergo-annotations/","text":"ergo-annotations \u00b6 Module defining the core annotations required for ergo, namely @Task It is used by the core ergo, in ergo-runtime , and exposed as API dependency to the client application. Providing Task Metadata in codebase \u00b6 Annotate the relevant functions with Task and provide a suitable taskId as argument (will be later used in code generation to map the taskId to this function call) import headout.oss.ergo.annotations.Task class ExampleTasks { @Task ( \"noArg\" ) fun noArg (): Boolean { // some long running execution return true } }","title":"Ergo Annotations"},{"location":"ergo-annotations/#ergo-annotations","text":"Module defining the core annotations required for ergo, namely @Task It is used by the core ergo, in ergo-runtime , and exposed as API dependency to the client application.","title":"ergo-annotations"},{"location":"ergo-annotations/#providing-task-metadata-in-codebase","text":"Annotate the relevant functions with Task and provide a suitable taskId as argument (will be later used in code generation to map the taskId to this function call) import headout.oss.ergo.annotations.Task class ExampleTasks { @Task ( \"noArg\" ) fun noArg (): Boolean { // some long running execution return true } }","title":"Providing Task Metadata in codebase"},{"location":"ergo-processor/","text":"ergo-processor \u00b6 Kapt-enabled module to run annotation processor, on compilation, used to generate required TaskController subclasses for parsing of request data, validation and execution of task Installation \u00b6 Add following to Gradle: Kotlin DSL (build.gradle.kts) plugins { kotlin ( \"kapt\" ) version kotlinVersion // Enable kapt plugin for annotation processing } dependencies { kapt ( \"com.github.headout.ergo-kotlin:ergo-processor:1.2.0\" ) } Groovy (build.gradle) plugins { id 'org.jetbrains.kotlin.kapt' version kotlinVersion // Enable kapt plugin for annotation processing } dependencies { kapt \"com.github.headout.ergo-kotlin:ergo-processor:1.2.0\" }","title":"Ergo Processor"},{"location":"ergo-processor/#ergo-processor","text":"Kapt-enabled module to run annotation processor, on compilation, used to generate required TaskController subclasses for parsing of request data, validation and execution of task","title":"ergo-processor"},{"location":"ergo-processor/#installation","text":"Add following to Gradle: Kotlin DSL (build.gradle.kts) plugins { kotlin ( \"kapt\" ) version kotlinVersion // Enable kapt plugin for annotation processing } dependencies { kapt ( \"com.github.headout.ergo-kotlin:ergo-processor:1.2.0\" ) } Groovy (build.gradle) plugins { id 'org.jetbrains.kotlin.kapt' version kotlinVersion // Enable kapt plugin for annotation processing } dependencies { kapt \"com.github.headout.ergo-kotlin:ergo-processor:1.2.0\" }","title":"Installation"},{"location":"ergo-runtime/","text":"ergo-runtime \u00b6 A common module defining the core logic for Base Ergo Message Service, task & job controllers, instance locator factory, data classes and other helper functions","title":"Ergo Runtime"},{"location":"ergo-runtime/#ergo-runtime","text":"A common module defining the core logic for Base Ergo Message Service, task & job controllers, instance locator factory, data classes and other helper functions","title":"ergo-runtime"},{"location":"ergo-service-sqs/","text":"ergo-service-sqs \u00b6 Module defining SQS Message service to communicate with SQS FIFO queues, using AWS Java SDK v2, to pick up tasks and push job results Requires \"software.amazon.awssdk:sqs\" to be added as implementation dependency in your project Installation \u00b6 Add following to Gradle: Kotlin DSL (build.gradle.kts) dependencies { implementation ( platform ( \"software.amazon.awssdk:bom:2.13.26\" )) implementation ( \"software.amazon.awssdk:sqs\" ) implementation ( \"com.github.headout.ergo-kotlin:ergo-service-sqs:1.2.0\" ) } Groovy (build.gradle) dependencies { implementation platform(\"software.amazon.awssdk:bom:2.13.26\") implementation \"software.amazon.awssdk:sqs\" implementation \"com.github.headout.ergo-kotlin:ergo-service-sqs:1.2.0\" } How to use it? \u00b6 import headout.oss.ergo.services.SqsMsgService import headout.oss.ergo.helpers.InMemoryBufferJobResultHandler val service = SqsMsgService ( sqsClient , REQUEST_QUEUE_URL , RESULT_QUEUE_URL , numWorkers = 20 , resultHandler = InMemoryBufferJobResultHandler ( 10 ) ) Existing Result Handlers: \u00b6 ImmediateRespondJobResultHandler : Pushes the result as soon as the job is finished/errored. It may be SQS request-intensive on the result queue. InMemoryBufferJobResultHandler : (default) Supports batching of job results and pushes in bulk upto 10 messages at a time. Architecture \u00b6 SQS Message Schema \u00b6 MessageBody must be stringified JSON for tasks with atleast one parameter. Key of the JSON will be the parameter name. Example: import software.amazon.awssdk.services.sqs.model.SendMessageRequest val sendMsg = SendMessageRequest . builder () . messageGroupId ( \"exampleTask\" ) . messageBody ( \"{\\\"i\\\": 1, \\\"hi\\\": \\\"whatever\\\"}\" ) . queueUrl ( REQUEST_QUEUE_URL ) . build () // for task with following signature: @Task ( \"exampleTask\" ) fun functionTask ( i : Int , hi : String ): Any MessageGroupId must refer to the taskId defined in the consumer client. Keep in mind that SQS FIFO queues do not allow receiving messages belonging to same MessageGroupId that is being consumed at the moment. So new task requests with same taskId can only be picked once all the previous tasks have finished executing. Complete flow with Airflow (SQS as message service) \u00b6 Notes and Sequence Diagram","title":"Ergo SQS Service"},{"location":"ergo-service-sqs/#ergo-service-sqs","text":"Module defining SQS Message service to communicate with SQS FIFO queues, using AWS Java SDK v2, to pick up tasks and push job results Requires \"software.amazon.awssdk:sqs\" to be added as implementation dependency in your project","title":"ergo-service-sqs"},{"location":"ergo-service-sqs/#installation","text":"Add following to Gradle: Kotlin DSL (build.gradle.kts) dependencies { implementation ( platform ( \"software.amazon.awssdk:bom:2.13.26\" )) implementation ( \"software.amazon.awssdk:sqs\" ) implementation ( \"com.github.headout.ergo-kotlin:ergo-service-sqs:1.2.0\" ) } Groovy (build.gradle) dependencies { implementation platform(\"software.amazon.awssdk:bom:2.13.26\") implementation \"software.amazon.awssdk:sqs\" implementation \"com.github.headout.ergo-kotlin:ergo-service-sqs:1.2.0\" }","title":"Installation"},{"location":"ergo-service-sqs/#how-to-use-it","text":"import headout.oss.ergo.services.SqsMsgService import headout.oss.ergo.helpers.InMemoryBufferJobResultHandler val service = SqsMsgService ( sqsClient , REQUEST_QUEUE_URL , RESULT_QUEUE_URL , numWorkers = 20 , resultHandler = InMemoryBufferJobResultHandler ( 10 ) )","title":"How to use it?"},{"location":"ergo-service-sqs/#existing-result-handlers","text":"ImmediateRespondJobResultHandler : Pushes the result as soon as the job is finished/errored. It may be SQS request-intensive on the result queue. InMemoryBufferJobResultHandler : (default) Supports batching of job results and pushes in bulk upto 10 messages at a time.","title":"Existing Result Handlers:"},{"location":"ergo-service-sqs/#architecture","text":"","title":"Architecture"},{"location":"ergo-service-sqs/#sqs-message-schema","text":"MessageBody must be stringified JSON for tasks with atleast one parameter. Key of the JSON will be the parameter name. Example: import software.amazon.awssdk.services.sqs.model.SendMessageRequest val sendMsg = SendMessageRequest . builder () . messageGroupId ( \"exampleTask\" ) . messageBody ( \"{\\\"i\\\": 1, \\\"hi\\\": \\\"whatever\\\"}\" ) . queueUrl ( REQUEST_QUEUE_URL ) . build () // for task with following signature: @Task ( \"exampleTask\" ) fun functionTask ( i : Int , hi : String ): Any MessageGroupId must refer to the taskId defined in the consumer client. Keep in mind that SQS FIFO queues do not allow receiving messages belonging to same MessageGroupId that is being consumed at the moment. So new task requests with same taskId can only be picked once all the previous tasks have finished executing.","title":"SQS Message Schema"},{"location":"ergo-service-sqs/#complete-flow-with-airflow-sqs-as-message-service","text":"Notes and Sequence Diagram","title":"Complete flow with Airflow (SQS as message service)"},{"location":"sample/","text":"Ergo client Samples \u00b6 You can find some sample tasks to help guide you in integrating ergo-kotlin in your project. Providing Task Metadata in codebase \u00b6 You can find some sample task definitions for static functions and suspending functions. Annotate the relevant functions with Task and provide a suitable taskId as argument (will be later used in code generation to map the taskId to this function call) import headout.oss.ergo.annotations.Task class ExampleTasks { @Task ( \"noArg\" ) fun noArg (): Boolean { // some long running execution return true } } If using custom data class as task parameter, make sure it\u2019s serializable. The return type must also be serializable: import headout.oss.ergo.annotations.Task import kotlinx.serialization.Serializable object ExampleTasks { @Task ( \"serializableArg\" ) @JvmStatic fun serializableArg ( request : Request ): Result { return Result ( request . somethingImportant ) } } @Serializable data class Request ( val somethingImportant : Int ) @Serializable data class Result ( val number : Int ) Here\u2019s an example for a suspending function task: import headout.oss.ergo.annotations.Task import kotlinx.coroutines.delay class ExampleTasks { @Task ( \"suspendingTask\" ) suspend fun longRunningTask ( input : Int ): Int { delay ( 20000L ) return input * input } } Spring Tasks \u00b6 You can find some sample task defintions for a task in spring service. The constructor also has an @Autowired property for a sample spring bean. Using Ergo\u2019s Message Service \u00b6 1. SQS service \u00b6 You can find the sample code for service here . Create SQS client and SQS Message Service (with default number of workers, 8, and result handler, In-Memory Buffer Results): const val AWS_REGION : Region = Region . US_EAST_1 // The following Queues must be of FIFO queue type since only FIFO queue supports MessageGroupId const val REQUEST_QUEUE_URL = \"...\" const val RESULT_QUEUE_URL = \"...\" val sqsClient = SqsAsyncClient . builder () . region ( AWS_REGION ) . build () val service = SqsMsgService ( sqsClient , REQUEST_QUEUE_URL , RESULT_QUEUE_URL ) Start the message service on application start: service . start () // Launches bunch of coroutines When needed, stop the message service: service . stop () To add a graceful shutdown of all worker coroutines, use Runtime.addShutdownHook function: Runtime . getRuntime (). addShutdownHook ( object : Thread () { override fun run () { super . run () service . stop () } })","title":"Sample"},{"location":"sample/#ergo-client-samples","text":"You can find some sample tasks to help guide you in integrating ergo-kotlin in your project.","title":"Ergo client Samples"},{"location":"sample/#providing-task-metadata-in-codebase","text":"You can find some sample task definitions for static functions and suspending functions. Annotate the relevant functions with Task and provide a suitable taskId as argument (will be later used in code generation to map the taskId to this function call) import headout.oss.ergo.annotations.Task class ExampleTasks { @Task ( \"noArg\" ) fun noArg (): Boolean { // some long running execution return true } } If using custom data class as task parameter, make sure it\u2019s serializable. The return type must also be serializable: import headout.oss.ergo.annotations.Task import kotlinx.serialization.Serializable object ExampleTasks { @Task ( \"serializableArg\" ) @JvmStatic fun serializableArg ( request : Request ): Result { return Result ( request . somethingImportant ) } } @Serializable data class Request ( val somethingImportant : Int ) @Serializable data class Result ( val number : Int ) Here\u2019s an example for a suspending function task: import headout.oss.ergo.annotations.Task import kotlinx.coroutines.delay class ExampleTasks { @Task ( \"suspendingTask\" ) suspend fun longRunningTask ( input : Int ): Int { delay ( 20000L ) return input * input } }","title":"Providing Task Metadata in codebase"},{"location":"sample/#spring-tasks","text":"You can find some sample task defintions for a task in spring service. The constructor also has an @Autowired property for a sample spring bean.","title":"Spring Tasks"},{"location":"sample/#using-ergos-message-service","text":"","title":"Using Ergo's Message Service"},{"location":"sample/#1-sqs-service","text":"You can find the sample code for service here . Create SQS client and SQS Message Service (with default number of workers, 8, and result handler, In-Memory Buffer Results): const val AWS_REGION : Region = Region . US_EAST_1 // The following Queues must be of FIFO queue type since only FIFO queue supports MessageGroupId const val REQUEST_QUEUE_URL = \"...\" const val RESULT_QUEUE_URL = \"...\" val sqsClient = SqsAsyncClient . builder () . region ( AWS_REGION ) . build () val service = SqsMsgService ( sqsClient , REQUEST_QUEUE_URL , RESULT_QUEUE_URL ) Start the message service on application start: service . start () // Launches bunch of coroutines When needed, stop the message service: service . stop () To add a graceful shutdown of all worker coroutines, use Runtime.addShutdownHook function: Runtime . getRuntime (). addShutdownHook ( object : Thread () { override fun run () { super . run () service . stop () } })","title":"1. SQS service"}]}